---
title: 2025JS
date: 2025-06-09
category:
  - Python
---



### 2.4-请求

```python
import requests

url = 'https://www.eastmoney.com/'


response = requests.get(url)
status = response.status_code

# 需要和下面写入文件的编码格式一样，不然会乱码
response.encoding = 'utf-8'
print(status)


if status == 200:
    page_text = response.text
    with open('test.html', 'w', encoding='utf-8') as f:
        f.write(page_text)
```

### 2.5-请求参数

```python
import requests

url = 'https://game.51.com/search/action/game/'

game_title = input('请输入一个游戏名称：')
params = {'q':game_title}
response = requests.get(url,params)
page_text = response.text

file_name = game_title + '.html'
with open(file_name, 'w', encoding='utf-8') as f:
    f.write(page_text)
```

### 2.5-反爬例子

```python
import requests

url = 'http://www.cpta.com.cn/'
response = requests.get(url)
page_text = response.text
with open('kaoshi.html', 'w', encoding='utf-8') as f:
    f.write(page_text)
```

被拦截：

![image-20250609154416604](http://www.iocaop.com/images/2025-06/20250609154416749.png)

加上UA:

```python
import requests

url = 'http://www.cpta.com.cn/'
headers = {'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36'}
response = requests.get(url, headers=headers)
page_text = response.text
with open('kaoshi.html', 'w', encoding='utf-8') as f:
    f.write(page_text)
```

可以正常获取数据。

![image-20250609155626936](http://www.iocaop.com/images/2025-06/20250609155627018.png)

### 2.7-post

```python
import requests

url = 'http://www.cpta.com.cn/category/search'
headers = {'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36'}
data = {
"keywords":"财务管理",
" 搜 索":"搜 索"
}
response = requests.post(url, headers=headers,data=data)
page_text = response.text
with open('财务管理.html', 'w', encoding='utf-8') as f:
    f.write(page_text)
```

### 2.8-动态加载数据

```python
import requests
headers = {
    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
    # 需加上，此站有防盗链
    'referer': 'https://www.icve.com.cn/portal_new/course/course.html?keyvalue=%E6%9C%BA%E6%A2%B0'
}
data = {
    "kczy": "",
    "order": "",
    "printstate": "",
    "keyvalue": "机械"
}

for page in range(1, 11):
    if page == 1:
        url = 'https://www.icve.com.cn/portal/course/getNewCourseInfo'
    else:
        # 格式化字符串
        url = 'https://www.icve.com.cn/portal/course/getNewCourseInfo?page=%d' % page
    response = requests.post(url, headers=headers, data=data)
    # 用response.json()将数据转成Python对象类型dict
    json_data = response.json()
    course_list = json_data['list']
    for course in course_list:
        print(course['TeacherDisplayname'])
```

### 2.9-图片爬取

```python
import requests
headers = {
    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',
}

img_url = 'http://gips2.baidu.com/it/u=1674525583,3037683813&fm=3028&app=3028&f=JPEG&fmt=auto?w=1024&h=1024'
response = requests.get(img_url, headers=headers)

# 二进制数据获取，对标Java的字节流
c = response.content
with open('image.jpg', 'wb') as f:
    f.write(c)
```

### 3.2-xpath

安装：

```python
pip install lxml
```

示例html:

```html
<html lang="en">
<head>
	<meta charset="UTF-8" />
	<title>测试bs4</title>
</head>
<body>
	<div>
		<p>百里守约</p>
	</div>
	<div class="song">
		<p>李清照</p>
		<p>王安石</p>
		<p>苏轼</p>
		<p>柳宗元</p>
		<a href="http://www.song.com/" title="赵匡胤" target="_self">
			<span>this is span</span>
		宋朝是最强大的王朝，不是军队的强大，而是经济很强大，国民都很有钱</a>
		<a href="" class="du">总为浮云能蔽日,长安不见使人愁</a>
		<img src="http://www.baidu.com/meinv.jpg" alt="" />
	</div>
	<div class="tang">
		<ul>
			<li><a href="http://www.baidu.com" title="qing">清明时节雨纷纷,路上行人欲断魂,借问酒家何处有,牧童遥指杏花村</a></li>
			<li><a href="http://www.163.com" title="qin">秦时明月汉时关,万里长征人未还,但使龙城飞将在,不教胡马度阴山</a></li>
			<li><a href="http://www.126.com" alt="qi">岐王宅里寻常见,崔九堂前几度闻,正是江南好风景,落花时节又逢君</a></li>
			<li><a href="http://www.sina.com" class="du">杜甫</a></li>
			<li><a href="http://www.dudu.com" class="du">杜牧</a></li>
			<li><b>杜小月</b></li>
			<li><i>度蜜月</i></li>
			<li><a href="http://www.haha.com" id="feng">凤凰台上凤凰游,凤去台空江自流,吴宫花草埋幽径,晋代衣冠成古丘</a></li>
		</ul>
	</div>
</body>
</html>
```

```python
from lxml import etree

# 1.创建etree对象，将html加载
tree = etree.parse('day03-3.2.html')
# 2.调用xpath函数，结合表达式提取数据

# 写法1：全局匹配
ret = tree.xpath('//title')
# 返回结果ret是一个列表
print(ret)
# 写法2 路径匹配
ret = tree.xpath('/html/head/title')
print(ret[0])

# 会定位到满足要求的所有标签
div_ret = tree.xpath('//div')
print(div_ret)

# 根据属性定位
div_class_ret = tree.xpath('//div[@class="song"]')
print(div_class_ret)

# 索引定位：所以 从1开始
index_ret = tree.xpath('//div[1]')
print(index_ret)

# 写法举例：全局匹配满足层级关系
demo1 = tree.xpath('//div/ul/li/a')
print(demo1)

# /表示一层  // 表示1层或多层
demo2 = tree.xpath('//ul//a')
print(demo2)

#取出文本
demo3 = tree.xpath('//div/a[@class="du"]/text()')
print(demo3)
```

### 3.3-小说《碧血剑》爬取

*  url：https://bixuejian.5000yan.com/ 

- 需求：将每一个章节的标题和内容进行爬取然后存储到文件中'

```python
import os

import requests
from lxml import etree

main_url = 'https://bixuejian.5000yan.com/'
response = requests.get(main_url)
response.encoding = 'utf-8'
page_text = response.text
# print(page_text)

tree = etree.HTML(response.text)
a_list = tree.xpath('//ul[@class="mx-auto  row row-cols-1 row-cols-sm-2 row-cols-lg-3"]//a')

os.makedirs('./xiaoshuo_lib', exist_ok=True)
for a in a_list:
    a_href = a.xpath('@href')[0]
    a_text = a.xpath('text()')[0]
    # print(a_text,a_href)
    res = requests.get(a_href)
    res.encoding = 'utf-8'
    tree = etree.HTML(res.text)
    p_list = tree.xpath('//div[@class="grap"]//text()')
    content = ''.join(p_list)
    with open(f'./xiaoshuo_lib/{a_text}.txt', 'w', encoding='utf-8') as f:
        f.write(content)

```

谷歌浏览器可以生成表达式：

![image-20250609184614669](http://www.iocaop.com/images/2025-06/20250609184614741.png)

### 3.4-简历爬取

* 简历模版下载：https://sc.chinaz.com/jianli/free.html
* 下载当前页所有的简历模板

```python
import os

import requests
from lxml import etree

os.makedirs('./jianli_lib', exist_ok=True)
url = 'https://sc.chinaz.com/jianli/free.html'
res = requests.get(url)
res.encoding = 'utf-8'
# print(res.text)
tree = etree.HTML(res.text)
a_list = tree.xpath('//div[@class="box col3 ws_block"]/p/a')
for a in a_list:
    a_href = a.xpath('@href')[0]
    a_text = a.xpath('text()')[0]
    # print(a_href, a_text)
    a_res = requests.get(a_href)
    a_res.encoding = 'utf-8'
    a_tree = etree.HTML(a_res.text)
    a_down = a_tree.xpath('//*[@id="down"]/div[2]/ul/li[3]/a')
    for a in a_down:
        a_down_href = a.xpath('@href')[0]
        a_down_text = a.xpath('text()')[0]
        print(a_down_href, a_down_text)
        resp = requests.get(a_down_href)
        with open("jianli_lib/"+a_text+".rar","wb") as f:
            f.write(resp.content)

```

